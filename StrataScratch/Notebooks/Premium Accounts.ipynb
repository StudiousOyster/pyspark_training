{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707a8ec1",
   "metadata": {},
   "source": [
    "## Premium Accounts\n",
    "You have a dataset that records daily active users for each premium account. A premium account appears in the data every day as long as it remains premium. However, some premium accounts may be temporarily discounted, meaning they are not actively payingâ€”this is indicated by a final_price of 0.\n",
    "\n",
    "\n",
    "For each of the first 7 available dates, count the number of premium accounts that were actively paying on that day. Then, track how many of those same accounts remain premium and are still paying exactly 7 days later (regardless of activity in between).\n",
    "\n",
    "\n",
    "Output three columns:\n",
    "- The date of initial calculation.\n",
    "- The number of premium accounts that were actively paying on that day.\n",
    "- The number of those accounts that remain premium and are still paying after 7 days.\n",
    "\n",
    "<br> <br>\n",
    "Table: premium_accounts_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90a07170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aef03ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34e24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"C:/Program Files/Java/jdk-11\"\n",
    "spark = SparkSession.builder.appName('Premium Accounts').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8198c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------+-----------+---------+\n",
      "|account_id|entry_date|users_visited_7d|final_price|plan_size|\n",
      "+----------+----------+----------------+-----------+---------+\n",
      "|       A01|2022-02-07|               1|        100|       10|\n",
      "|       A03|2022-02-07|              30|        400|       50|\n",
      "|       A01|2022-02-08|               3|        100|       10|\n",
      "|       A03|2022-02-08|              39|        400|       50|\n",
      "|       A05|2022-02-08|              14|        400|       50|\n",
      "|       A01|2022-02-09|              12|        100|       10|\n",
      "|       A03|2022-02-09|              44|        400|       50|\n",
      "|       A04|2022-02-09|              25|          0|       70|\n",
      "|       A05|2022-02-09|              32|        400|       50|\n",
      "|       A01|2022-02-10|              17|        100|       10|\n",
      "|       A02|2022-02-10|              82|        800|      100|\n",
      "|       A03|2022-02-10|              60|        400|       50|\n",
      "|       A04|2022-02-10|              72|          0|       70|\n",
      "|       A05|2022-02-10|              45|        400|       50|\n",
      "|       A01|2022-02-11|              26|        100|       10|\n",
      "|       A02|2022-02-11|             102|        800|      100|\n",
      "|       A03|2022-02-11|              76|        400|       50|\n",
      "|       A04|2022-02-11|             115|          0|       70|\n",
      "|       A05|2022-02-11|              50|        400|       50|\n",
      "|       A01|2022-02-12|              28|        100|       10|\n",
      "+----------+----------+----------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .load('../Data/premium_accounts_by_day.csv')\n",
    "    \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22635cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+------------------------------+\n",
      "|entry_date|premium_paid_accounts|premium_paid_accounts_after_7d|\n",
      "+----------+---------------------+------------------------------+\n",
      "|2022-02-07|                    2|                             2|\n",
      "|2022-02-08|                    3|                             2|\n",
      "|2022-02-09|                    3|                             2|\n",
      "|2022-02-10|                    4|                             3|\n",
      "|2022-02-11|                    4|                             1|\n",
      "|2022-02-12|                    4|                             2|\n",
      "|2022-02-13|                    4|                             1|\n",
      "+----------+---------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df.filter(\n",
    "    F.col('final_price') > 0    \n",
    "    )\n",
    "        \n",
    "result = result.withColumn(\n",
    "    'after_7days',\n",
    "    F.date_add(F.col('entry_date'), 7)\n",
    "    )\n",
    "\n",
    "result = result.alias('r1').join(\n",
    "    result.alias('r2'),\n",
    "    (F.col('r1.after_7days') == F.col('r2.entry_date')) & (F.col('r1.account_id') == F.col('r2.account_id')),\n",
    "    how = 'left'\n",
    "    ).select(\n",
    "        F.col('r1.entry_date'),\n",
    "        F.col('r1.account_id').alias('initial_account_id'),\n",
    "        F.col('r2.account_id').alias('after7_account_id')\n",
    "        )\n",
    "    \n",
    "final_result = result.groupBy(\n",
    "    'entry_date'\n",
    "    ).agg(\n",
    "        F.count('initial_account_id').alias('premium_paid_accounts'),\n",
    "        F.count('after7_account_id').alias('premium_paid_accounts_after_7d')\n",
    "        ).orderBy(\n",
    "            'entry_date'\n",
    "            ).limit(7).toPandas()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec649d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
